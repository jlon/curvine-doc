---
authors: [david]
tags: [benchmark, starrocks, storage]
---

<!-- truncate -->

# 实测！StarRocks存算分离性能大揭秘：Curvine缓存竟有这波神操作

在云上部署场景中，存算分离架构凭借对象存储的低成本和弹性算力优势，成为越来越多企业的选择。而 StarRocks 作为高性能数据仓库，其存算分离模式的表现一直备受关注——既要享受成本红利，又担心性能损耗，这是很多开发者的核心顾虑。

今天，我们通过标准 **TPC-DS benchmark** 测试，全面对比存算一体（SSD/HDD）与存算分离（Curvine/OSS）架构的查询性能，并说明高性能缓存如何缓解存算分离的性能痛点。

---

## 一、测试背景：为什么要做这场对比？

本次测试核心目标是评估**不同存储架构、磁盘类型**对 StarRocks 查询性能的影响。在**完全相同的计算资源**环境下，针对 24 个表的 **99 个复杂 SQL**，开展 TPC-DS 100GB 标准基准测试，重点对比查询总时间、平均耗时等关键指标。

**测试环境速览**

| 项目 | 说明 |
|------|------|
| 计算节点 | 阿里云 ecs.r6.8xlarge（32C/256G），所有架构均为 3 节点集群 |
| 测试分组 | 5 组对照：存算一体 SSD/HDD、存算分离 Curvine SSD/HDD、存算分离原生 OSS |
| 数据集 | TPC-DS 100GB，99 个标准复杂 SQL |

---

## 二、核心结论：4 个关键发现

**1. 架构影响 ＞ 介质影响**  
存算一体架构的查询性能普遍优于存算分离架构，主要因为存算一体避免了跨节点数据传输的网络开销。

**2. Curvine 缓存：存算分离的性能救星**  
同为存算分离架构，**Curvine SSD（总耗时 362s）** 比 **原生 OSS（419s）** 快约 **16%**。在私有化部署场景中，用 Curvine 替代公有云对象存储，能获得明显性能提升。

**3. SSD 介质：全场景性能优势**  
无论存算一体还是 Curvine 存算分离，SSD 磁盘的性能始终优于 HDD，在大数据量扫描场景中尤为明显。

**4. OSS：性价比之王**  
原生 OSS 方案虽然最慢，但仅比最快的存算一体 SSD 方案慢约 **41%**。考虑到其极低的存储成本和弹性扩展能力，在非极致性能敏感场景中性价比很高。

---

## 三、测试结果：详细数据对比

| 性能指标 | 存算一体 (SSD) | 存算一体 (HDD) | 存算分离 (Curvine SSD) | 存算分离 (Curvine HDD) | 存算分离 (OSS) |
|----------|----------------|----------------|-------------------------|-------------------------|----------------|
| **总耗时** | 297.96 秒 | 313.68 秒 | 361.86 秒 | 385.20 秒 | 419.15 秒 |
| **相对性能** | 基准 (100%) | 慢 5.3% | 慢 21.4% | 慢 29.3% | 慢 40.7% |
| **平均耗时** | 3.01 秒 | 3.17 秒 | 3.66 秒 | 3.89 秒 | 4.23 秒 |
| **最慢查询** | 52.94 秒 | 54.40 秒 | 54.87 秒 | 55.19 秒 | 52.66 秒 |

从数据可见：存算一体 SSD 表现最佳，总耗时不足 300 秒；Curvine 存算分离架构大幅缩小了与存算一体的差距，尤其是 Curvine SSD 版本；即使是最慢的 OSS 方案，平均耗时也仅 4.23 秒，满足大部分业务场景需求。

---

## 四、痛点破解：存算分离慢查询优化实录

测试中发现 2 个典型慢查询（sql-05、sql-77），存算分离与存算一体的耗时差距达 **5–8 倍**。通过分析，我们定位到原因并给出解决方案。

### Query 05：8 倍性能差距的根源

- **现象**：存算分离约 15s，存算一体约 1.8s。
- **原因**：3 表 Union 产生约 2.75 亿行明细数据（15.33GB），跨节点全量传输导致网络瓶颈（占时约 10s）。
- **核心矛盾**：存算分离架构下，数据需远程读取并传输，而存算一体可直接读本地数据。

### Query 77：全量扫描的性能陷阱

- **现象**：存算分离约 11s，存算一体约 1.8s。
- **原因**：涉及约 2.88 亿行数据全表扫描（14.43GB），远程读取的网络 I/O 效率远低于本地 SSD；优化器「预聚合」策略阻断了「动态过滤」功能，导致无效数据全量传输。

**解决方案：一行参数显著提升性能**

禁用聚合下推参数，恢复动态过滤功能：

```sql
SET cbo_push_down_aggregate_mode = -1;
```

**优化效果**：扫描行数从约 2.75 亿降至约 611 万，性能直接追平存算一体水平。

---

## 五、总结与选型建议

| 目标 | 建议 |
|------|------|
| **追求极致性能** | 选择存算一体 SSD 架构，适合实时分析、高并发查询场景。 |
| **私有化部署 + 成本敏感** | 优先 Curvine 存算分离架构（推荐 SSD 版本），兼顾性能与弹性。 |
| **公有云 + 海量存储** | 原生 OSS 存算分离方案，性价比突出，适合非实时分析场景。 |
| **已用存算分离** | 执行上述优化参数，规避慢查询陷阱，性能可大幅提升。 |

存算分离并非「性能妥协」。通过 Curvine 高性能分布式缓存与针对性优化，StarRocks 完全能在享受低成本、高弹性的同时，保持优异的查询性能。
